# machine learning methods


## linear regression

- predict continuous outcome y
- mean value of response is linear function (dot-product)
- normal distributed error e
- maximum likelihood = least squares solution (squared errors minimized)

- log-normal data + linear reg. = powerful tool

- categorical data can be binary
- if variable takes > 2 values ==> use dummy variable (one-hot encoding)


## logistic regression

- not regression ==> response binary
- output probability of outcome 
- "linear regression" B^tx but mapping through sigmoid function
- sigmoid limited between [0, 1]
- log (P(Y=1) / P(Y=0)) = B^tx
- will increase log-odds

## decision trees

- root and leaves
- can be either
	* deterministic
	* probabilistic

- random forests = build many trees and average them (allow trees to only use a random subset)






 

